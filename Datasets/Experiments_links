Here are the instructions to build up eight different datasets each one obtained by union of:

* a set of reads (setA2_1, setA2_2, setB2_1, setB2_2)
* a set of genomes (reference database). 

### Sets of reads

The sets of simulated paired end reads we used for experiments are downloadable from 

http://www.gardner-binflab.org/lindgreen-et-al-metagenomics-benchmark-data/

and were designed ad hoc for a benchmarking analysis of metagenomic tools by reproducing the size, complexity and characteristics of real metagenomic samples. 
Moreover, Lindgreen's datasets were designed to include subsets of simulated shuffled reads as negative controls in order to test the reliability of the tools.

For our experiments, we selected the sets setA2 (setA2_1, setA2_2) and setB2 (setB2_1, setB2_2) and we modified the content of each fasta file as follows. 

We took the random shuffled whose titles are in files title_setA2ran.txt.gz and title_setB2ran.txt.gz, respectively.
We removed from setA2 and from setB2 a group of reads associated with the phylum of Eukaryotes whose species provenance was not specified.
In addition, we preferred to discard also a group of reads whose associated genomes are expiring entries in the NCBI database being obsolete or incorrect. 
Each set of considered reads of setA2 and setB2 thus contains around 20 millions of sequences belonging to 17 different phyla and 686 species. 
The complete list of reads taken into account in setA2 and setB2 is partitioned in files title_setA2_part_.gz* and title_setB2_part_.gz*, respectively.
To decompress them one could use the command cat compressed.gz* | zcat > /path/to/decrompressed/file

### Reference database

The set of reference genomes were provided by Lindgreen et al. https://www.nature.com/articles/srep19233 in the Supplementary Table S2.
In Reference_database.csv we report accession numbers, phylum taxonomy ID, and species taxonomy ID for each of the 930 genomes considered in our datasets. 
